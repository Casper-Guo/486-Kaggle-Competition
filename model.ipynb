{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"wordnet\")\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier as AdaBoost, RandomForestClassifier as RandomForest, GradientBoostingClassifier as XGBoost\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, cross_val_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"train.csv\")\n",
    "df_test = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopword_list = set(stopwords.words(\"english\"))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess_str(input: str) -> str:\n",
    "    \"\"\"\n",
    "    Tokenize, remove stopwords, lemmatize, and then reassemble into one string.\n",
    "    \n",
    "    String type output required for easier ingestion by sklearn TfidfVectorizer\n",
    "    \"\"\"\n",
    "    \n",
    "    tokens = word_tokenize(input)\n",
    "    tokens = [token for token in tokens if token not in ['.', ','] and token not in stopword_list]\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    \n",
    "    return \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"processed\"] = df_train[\"text\"].apply(preprocess_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[\"processed\"] = df_test[\"text\"].apply(preprocess_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(strip_accents='ascii')\n",
    "train_processed_tfidf = vectorizer.fit_transform(df_train[\"processed\"])\n",
    "test_processed_tfidf = vectorizer.transform(df_test[\"processed\"])\n",
    "train_tfidf = vectorizer.fit_transform(df_train[\"text\"])\n",
    "test_tfidf = vectorizer.transform(df_test[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM = SVC(random_state=42)\n",
    "SVM_search = GridSearchCV(SVM, param_grid=[{\"kernel\":[\"linear\", \"rbf\"], \"C\":[0.1, 0.3, 1, 3, 10]}, {\"kernel\":[\"poly\"], \"degree\":list(range(2, 6))}], n_jobs=-1, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM_search.fit(train_tfidf, df_train[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_param = SVM_search.best_params_\n",
    "svm_score = SVM_search.best_score_\n",
    "print(svm_param, svm_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM_search.fit(train_processed_tfidf, df_train[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_processed_param = SVM_search.best_params_\n",
    "svm_processed_score = SVM_search.best_score_\n",
    "print(svm_processed_param, svm_processed_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB = MultinomialNB()\n",
    "NB_score = cross_val_score(NB, train_tfidf, df_train[\"label\"], cv=5, n_jobs=-1)\n",
    "NB_processed_score = cross_val_score(NB, train_processed_tfidf, df_train[\"label\"], cv=5, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Original text: \", NB_score.mean())\n",
    "print(\"Processed text: \", NB_processed_score.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = LogisticRegressionCV(Cs = [0.1, 0.3, 1, 3, 10, 30, 100, 300, 1000], fit_intercept=False, n_jobs=-1, random_state=42)\n",
    "LR_score = cross_val_score(LR, train_tfidf, df_train[\"label\"], cv=5, n_jobs=-1)\n",
    "LR_processed_score = cross_val_score(LR, train_processed_tfidf, df_train[\"label\"], cv=5, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Original text: \", LR_score.mean())\n",
    "print(\"Processed text: \", LR_processed_score.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ada = AdaBoost(random_state=42)\n",
    "Ada_search = GridSearchCV(Ada, param_grid = {\"n_estimators\":list(range(10, 101, 10)), \"learning_rate\":[0.1, 0.3, 1, 3, 10]}, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ada_search.fit(train_tfidf, df_train[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ada_param = Ada_search.best_params_\n",
    "Ada_score = Ada_search.best_score_\n",
    "print(Ada_param, Ada_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ada_search.fit(train_processed_tfidf, df_train[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ada_processed_param = Ada_search.best_params_\n",
    "Ada_processed_score = Ada_search.best_score_\n",
    "print(Ada_processed_param, Ada_processed_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF = RandomForest(n_jobs=-1, random_state=42)\n",
    "RF_Search = GridSearchCV(RF, param_grid={\"n_estimators\":list(range(50, 301, 50))}, n_jobs=-1, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_Search.fit(train_tfidf, df_train[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_param = RF_Search.best_params_\n",
    "RF_score = RF_Search.best_score_\n",
    "print(RF_param, RF_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_Search.fit(train_processed_tfidf, df_train[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_processed_param = RF_Search.best_params_\n",
    "RF_processed_score = RF_Search.best_score_\n",
    "print(RF_processed_param, RF_processed_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XG = XGBoost(random_state=42)\n",
    "XG_Search = GridSearchCV(XG, param_grid={\"learning_rate\": [0.01, 0.03, 0.1, 0.3, 1], \"n_estimators\": list(range(50, 301, 50)), \"subsample\": [0.5, 1]}, n_jobs=-1, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XG_Search.fit(train_tfidf, df_train[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XG_param = XG_Search.best_params_\n",
    "XG_score = XG_Search.best_score_\n",
    "print(XG_param, XG_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XG_Search.fit(train_processed_tfidf, df_train[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XG_processed_param = XG_Search.best_params_\n",
    "XG_processed_score = XG_Search.best_score_\n",
    "print(XG_processed_param, XG_processed_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN = KNeighborsClassifier(n_jobs=-1)\n",
    "KNN_Search = GridSearchCV(KNN, param_grid={\"n_neighbors\":[2, 4, 6, 8, 10], \"weights\": [\"uniform\", \"distance\"]}, n_jobs=-1, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN_Search.fit(train_tfidf, df_train[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN_param = KNN_Search.best_params_\n",
    "KNN_score = KNN_Search.best_score_\n",
    "print(KNN_param, KNN_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN_Search.fit(train_processed_tfidf, df_train[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN_processed_param = KNN_Search.best_params_\n",
    "KNN_processed_score = KNN_Search.best_score_\n",
    "print(KNN_processed_param, KNN_processed_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "classifier = pipeline(\"zero-shot-classification\",\n",
    "                      model=\"facebook/bart-large-mnli\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(sequence, labels, clf):\n",
    "    output = clf(sequence, labels)\n",
    "    return output[\"scores\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"false\", \"real\"]\n",
    "\n",
    "predict(df_test.iloc[500][\"text\"], labels, classifier)\n",
    "# df_test[\"HF\"] = df_test[\"text\"].apply(lambda sequence: predict(sequence, labels, classifier))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(clf, embedding):\n",
    "    Id = df_test[\"Id\"]\n",
    "    pred = pd.Series(clf.predict(embedding))\n",
    "    \n",
    "    return pd.DataFrame({'Id': Id, 'Category': pred})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM_pred = SVC(C=10, kernel=\"rbf\", random_state=42)\n",
    "SVM_pred.fit(train_tfidf, df_train[\"label\"])\n",
    "\n",
    "df_SVM = predict(SVM_pred, test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_SVM.to_csv(\"SVM.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_pred = RandomForest(n_estimators=300, n_jobs=-1, random_state=4)\n",
    "RF_pred.fit(train_tfidf, df_train[\"label\"])\n",
    "df_RF = predict(RF_pred, test_tfidf)\n",
    "df_RF.to_csv(\"RandomForest.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
